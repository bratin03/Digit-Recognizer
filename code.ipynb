{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/digit-recognizer/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "val_rate = 0.2\n",
    "val_num = int(data.shape[0] * val_rate)\n",
    "\n",
    "m, n=data.shape\n",
    "\n",
    "x_val = data[:val_num, 1:]\n",
    "t_val = data[:val_num, 0]\n",
    "x_train = data[val_num: , 1:]\n",
    "t_train = data[val_num: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.randn(784, 10) *0.01\n",
    "    b1 = np.zeros((1,10))\n",
    "    W2 = np.random.randn(10, 10) *0.01\n",
    "    b2 = np.zeros((1,10))\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "    x = x - np.max(x) \n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class propagation:\n",
    "    def __init__(self):\n",
    "        self.A1 = None\n",
    "        self.Z1 = None\n",
    "        self.A2 = None\n",
    "        self.Y = None\n",
    "        self.T = None\n",
    "        self.x = None\n",
    "        self.W2 = None\n",
    "    \n",
    "    def forward(self, x, W1, b1, W2, b2):\n",
    "        self.x = x\n",
    "        self.W2 = W2\n",
    "        self.A1 = np.dot(self.x, W1) + b1\n",
    "        self.Z1 = relu(self.A1)\n",
    "        self.A2 = np.dot(self.Z1, W2) + b2\n",
    "        self.Y = softmax(self.A2)\n",
    "    \n",
    "        return self.Y\n",
    "    \n",
    "    def backward(self, t):\n",
    "        self.T = num_key(t)\n",
    "        m = self.T.size\n",
    "        dA2 = (self.Y - self.T) / m\n",
    "        dW2 = np.dot(self.Z1.T, dA2)\n",
    "        db2 = np.sum(dA2, axis = 0)    \n",
    "        dZ1 = np.dot(dA2, self.W2.T)\n",
    "        dA1 = dZ1 * np.array(self.Z1 > 0, dtype=int)\n",
    "        db1 = np.sum(dA1, axis = 0) \n",
    "        dW1 = np.dot(self.x.T, dA1)\n",
    "        \n",
    "        return dW1, dW2, db1, db2\n",
    "def num_key(x):\n",
    "    x.reshape(1, x.size)\n",
    "    batch_size = len(x)\n",
    "    t = np.zeros((batch_size, 10))\n",
    "    t[np.arange(batch_size), x] = 1\n",
    "    \n",
    "    return t    \n",
    "\n",
    "def update(W1, b1, W2, b2, dW1, dW2, db1, db2, learning_rate):\n",
    "    db1.reshape(1, db1.size)\n",
    "    db2.reshape(1, db2.size)\n",
    "    lr = learning_rate\n",
    "    W1 = W1 - lr * dW1\n",
    "    W2 = W2 - lr * dW2\n",
    "    b1 = b1 - lr * db1\n",
    "    b2 = b2 - lr * db2\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def prediction(Y):\n",
    "    return np.argmax(Y, axis = 1)\n",
    "\n",
    "def accuracy(Y, t):\n",
    "    K = prediction(Y)\n",
    "    t.reshape(1, t.size)\n",
    "    return np.sum(K == t) / K.size\n",
    "\n",
    "\n",
    "def train_network(x, t, iter, learning_rate):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    prop = propagation()\n",
    "    \n",
    "    for i in range(iter):\n",
    "        Y = prop.forward(x, W1, b1, W2, b2)\n",
    "        dW1, dW2, db1, db2 = prop.backward(t)\n",
    "        W1, b1, W2, b2 = update(W1, b1, W2, b2, dW1, dW2, db1, db2, learning_rate)\n",
    "        if (i%10 == 0):\n",
    "            print('iteration: ', i)\n",
    "            print('accuracy: ', accuracy(Y, t))\n",
    "            \n",
    "            \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def test_network(x, t, W1, b1, W2, b2):\n",
    "    prop = propagation()\n",
    "    Y = prop.forward(x, W1, b1, W2, b2)\n",
    "    print(Y)\n",
    "    print(accuracy(Y, t))\n",
    "    return prediction(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "accuracy:  0.09047619047619047\n",
      "iteration:  10\n",
      "accuracy:  0.48523809523809525\n",
      "iteration:  20\n",
      "accuracy:  0.7334226190476191\n",
      "iteration:  30\n",
      "accuracy:  0.7825595238095238\n",
      "iteration:  40\n",
      "accuracy:  0.7897619047619048\n",
      "iteration:  50\n",
      "accuracy:  0.8211607142857142\n",
      "iteration:  60\n",
      "accuracy:  0.816577380952381\n",
      "iteration:  70\n",
      "accuracy:  0.8482142857142857\n",
      "iteration:  80\n",
      "accuracy:  0.8353273809523809\n",
      "iteration:  90\n",
      "accuracy:  0.8665178571428571\n",
      "iteration:  100\n",
      "accuracy:  0.8636011904761904\n",
      "iteration:  110\n",
      "accuracy:  0.8678571428571429\n",
      "iteration:  120\n",
      "accuracy:  0.8794047619047619\n",
      "iteration:  130\n",
      "accuracy:  0.8809523809523809\n",
      "iteration:  140\n",
      "accuracy:  0.8791964285714285\n",
      "iteration:  150\n",
      "accuracy:  0.8869047619047619\n",
      "iteration:  160\n",
      "accuracy:  0.8901488095238095\n",
      "iteration:  170\n",
      "accuracy:  0.8897619047619048\n",
      "iteration:  180\n",
      "accuracy:  0.8890178571428572\n",
      "iteration:  190\n",
      "accuracy:  0.8933333333333333\n",
      "iteration:  200\n",
      "accuracy:  0.8966369047619047\n",
      "iteration:  210\n",
      "accuracy:  0.8980357142857143\n",
      "iteration:  220\n",
      "accuracy:  0.8968452380952381\n",
      "iteration:  230\n",
      "accuracy:  0.8966666666666666\n",
      "iteration:  240\n",
      "accuracy:  0.9006547619047619\n",
      "iteration:  250\n",
      "accuracy:  0.9022916666666667\n",
      "iteration:  260\n",
      "accuracy:  0.9019345238095238\n",
      "iteration:  270\n",
      "accuracy:  0.8989583333333333\n",
      "iteration:  280\n",
      "accuracy:  0.9020535714285715\n",
      "iteration:  290\n",
      "accuracy:  0.9055059523809523\n",
      "iteration:  300\n",
      "accuracy:  0.9052083333333333\n",
      "iteration:  310\n",
      "accuracy:  0.9016964285714286\n",
      "iteration:  320\n",
      "accuracy:  0.8987797619047619\n",
      "iteration:  330\n",
      "accuracy:  0.9077678571428571\n",
      "iteration:  340\n",
      "accuracy:  0.9104464285714285\n",
      "iteration:  350\n",
      "accuracy:  0.9107142857142857\n",
      "iteration:  360\n",
      "accuracy:  0.9106547619047619\n",
      "iteration:  370\n",
      "accuracy:  0.9084821428571429\n",
      "iteration:  380\n",
      "accuracy:  0.9008630952380953\n",
      "iteration:  390\n",
      "accuracy:  0.9066071428571428\n",
      "iteration:  400\n",
      "accuracy:  0.9130952380952381\n",
      "iteration:  410\n",
      "accuracy:  0.9144642857142857\n",
      "iteration:  420\n",
      "accuracy:  0.9150892857142857\n",
      "iteration:  430\n",
      "accuracy:  0.9158928571428572\n",
      "iteration:  440\n",
      "accuracy:  0.9154464285714285\n",
      "iteration:  450\n",
      "accuracy:  0.9138392857142857\n",
      "iteration:  460\n",
      "accuracy:  0.9054464285714285\n",
      "iteration:  470\n",
      "accuracy:  0.90625\n",
      "iteration:  480\n",
      "accuracy:  0.9177083333333333\n",
      "iteration:  490\n",
      "accuracy:  0.9188988095238095\n",
      "iteration:  500\n",
      "accuracy:  0.9194642857142857\n",
      "iteration:  510\n",
      "accuracy:  0.9201785714285714\n",
      "iteration:  520\n",
      "accuracy:  0.9204761904761904\n",
      "iteration:  530\n",
      "accuracy:  0.9210119047619048\n",
      "iteration:  540\n",
      "accuracy:  0.9202678571428572\n",
      "iteration:  550\n",
      "accuracy:  0.9180059523809524\n",
      "iteration:  560\n",
      "accuracy:  0.9074702380952381\n",
      "iteration:  570\n",
      "accuracy:  0.9119642857142857\n",
      "iteration:  580\n",
      "accuracy:  0.9221428571428572\n",
      "iteration:  590\n",
      "accuracy:  0.9233630952380952\n",
      "iteration:  600\n",
      "accuracy:  0.9237202380952381\n",
      "iteration:  610\n",
      "accuracy:  0.924404761904762\n",
      "iteration:  620\n",
      "accuracy:  0.9244345238095238\n",
      "iteration:  630\n",
      "accuracy:  0.9245238095238095\n",
      "iteration:  640\n",
      "accuracy:  0.9246130952380952\n",
      "iteration:  650\n",
      "accuracy:  0.9232440476190477\n",
      "iteration:  660\n",
      "accuracy:  0.9158333333333334\n",
      "iteration:  670\n",
      "accuracy:  0.9002976190476191\n",
      "iteration:  680\n",
      "accuracy:  0.9254166666666667\n",
      "iteration:  690\n",
      "accuracy:  0.926875\n",
      "iteration:  700\n",
      "accuracy:  0.9274702380952381\n",
      "iteration:  710\n",
      "accuracy:  0.9277380952380953\n",
      "iteration:  720\n",
      "accuracy:  0.927797619047619\n",
      "iteration:  730\n",
      "accuracy:  0.9279761904761905\n",
      "iteration:  740\n",
      "accuracy:  0.928422619047619\n",
      "iteration:  750\n",
      "accuracy:  0.9285119047619048\n",
      "iteration:  760\n",
      "accuracy:  0.9289285714285714\n",
      "iteration:  770\n",
      "accuracy:  0.9286904761904762\n",
      "iteration:  780\n",
      "accuracy:  0.9270535714285715\n",
      "iteration:  790\n",
      "accuracy:  0.9191071428571429\n",
      "iteration:  800\n",
      "accuracy:  0.924047619047619\n",
      "iteration:  810\n",
      "accuracy:  0.9296428571428571\n",
      "iteration:  820\n",
      "accuracy:  0.9305059523809524\n",
      "iteration:  830\n",
      "accuracy:  0.9308333333333333\n",
      "iteration:  840\n",
      "accuracy:  0.9308928571428572\n",
      "iteration:  850\n",
      "accuracy:  0.9308333333333333\n",
      "iteration:  860\n",
      "accuracy:  0.9296130952380952\n",
      "iteration:  870\n",
      "accuracy:  0.9240178571428571\n",
      "iteration:  880\n",
      "accuracy:  0.9051190476190476\n",
      "iteration:  890\n",
      "accuracy:  0.9308630952380952\n",
      "iteration:  900\n",
      "accuracy:  0.9320238095238095\n",
      "iteration:  910\n",
      "accuracy:  0.9323511904761905\n",
      "iteration:  920\n",
      "accuracy:  0.9327380952380953\n",
      "iteration:  930\n",
      "accuracy:  0.9329464285714286\n",
      "iteration:  940\n",
      "accuracy:  0.9329166666666666\n",
      "iteration:  950\n",
      "accuracy:  0.9330357142857143\n",
      "iteration:  960\n",
      "accuracy:  0.9330059523809524\n",
      "iteration:  970\n",
      "accuracy:  0.9329464285714286\n",
      "iteration:  980\n",
      "accuracy:  0.9320833333333334\n",
      "iteration:  990\n",
      "accuracy:  0.9258035714285714\n",
      "iteration:  1000\n",
      "accuracy:  0.9101190476190476\n",
      "iteration:  1010\n",
      "accuracy:  0.9325297619047619\n",
      "iteration:  1020\n",
      "accuracy:  0.9344345238095239\n",
      "iteration:  1030\n",
      "accuracy:  0.934375\n",
      "iteration:  1040\n",
      "accuracy:  0.9341964285714286\n",
      "iteration:  1050\n",
      "accuracy:  0.9340773809523809\n",
      "iteration:  1060\n",
      "accuracy:  0.9341964285714286\n",
      "iteration:  1070\n",
      "accuracy:  0.9327678571428571\n",
      "iteration:  1080\n",
      "accuracy:  0.9214880952380953\n",
      "iteration:  1090\n",
      "accuracy:  0.838452380952381\n",
      "iteration:  1100\n",
      "accuracy:  0.9319047619047619\n",
      "iteration:  1110\n",
      "accuracy:  0.9340178571428571\n",
      "iteration:  1120\n",
      "accuracy:  0.9347321428571429\n",
      "iteration:  1130\n",
      "accuracy:  0.9353869047619048\n",
      "iteration:  1140\n",
      "accuracy:  0.9361011904761904\n",
      "iteration:  1150\n",
      "accuracy:  0.9362202380952381\n",
      "iteration:  1160\n",
      "accuracy:  0.9363988095238095\n",
      "iteration:  1170\n",
      "accuracy:  0.9364285714285714\n",
      "iteration:  1180\n",
      "accuracy:  0.9366964285714285\n",
      "iteration:  1190\n",
      "accuracy:  0.936875\n",
      "iteration:  1200\n",
      "accuracy:  0.9370833333333334\n",
      "iteration:  1210\n",
      "accuracy:  0.9370535714285714\n",
      "iteration:  1220\n",
      "accuracy:  0.9372916666666666\n",
      "iteration:  1230\n",
      "accuracy:  0.9374107142857143\n",
      "iteration:  1240\n",
      "accuracy:  0.9376190476190476\n",
      "iteration:  1250\n",
      "accuracy:  0.9376785714285715\n",
      "iteration:  1260\n",
      "accuracy:  0.9379464285714286\n",
      "iteration:  1270\n",
      "accuracy:  0.9379166666666666\n",
      "iteration:  1280\n",
      "accuracy:  0.9377380952380953\n",
      "iteration:  1290\n",
      "accuracy:  0.9347916666666667\n",
      "iteration:  1300\n",
      "accuracy:  0.9206547619047619\n",
      "iteration:  1310\n",
      "accuracy:  0.9238988095238095\n",
      "iteration:  1320\n",
      "accuracy:  0.9380654761904762\n",
      "iteration:  1330\n",
      "accuracy:  0.9389880952380952\n",
      "iteration:  1340\n",
      "accuracy:  0.9389285714285714\n",
      "iteration:  1350\n",
      "accuracy:  0.9390178571428571\n",
      "iteration:  1360\n",
      "accuracy:  0.9389285714285714\n",
      "iteration:  1370\n",
      "accuracy:  0.9390773809523809\n",
      "iteration:  1380\n",
      "accuracy:  0.9393154761904762\n",
      "iteration:  1390\n",
      "accuracy:  0.9394642857142858\n",
      "iteration:  1400\n",
      "accuracy:  0.9396428571428571\n",
      "iteration:  1410\n",
      "accuracy:  0.9397321428571429\n",
      "iteration:  1420\n",
      "accuracy:  0.9397619047619048\n",
      "iteration:  1430\n",
      "accuracy:  0.9398809523809524\n",
      "iteration:  1440\n",
      "accuracy:  0.9397916666666667\n",
      "iteration:  1450\n",
      "accuracy:  0.9392559523809524\n",
      "iteration:  1460\n",
      "accuracy:  0.9363095238095238\n",
      "iteration:  1470\n",
      "accuracy:  0.9245833333333333\n",
      "iteration:  1480\n",
      "accuracy:  0.9166369047619047\n",
      "iteration:  1490\n",
      "accuracy:  0.9396130952380952\n",
      "iteration:  1500\n",
      "accuracy:  0.9401488095238095\n",
      "iteration:  1510\n",
      "accuracy:  0.9406845238095238\n",
      "iteration:  1520\n",
      "accuracy:  0.9409226190476191\n",
      "iteration:  1530\n",
      "accuracy:  0.940952380952381\n",
      "iteration:  1540\n",
      "accuracy:  0.9411904761904762\n",
      "iteration:  1550\n",
      "accuracy:  0.9413690476190476\n",
      "iteration:  1560\n",
      "accuracy:  0.9413392857142857\n",
      "iteration:  1570\n",
      "accuracy:  0.9413392857142857\n",
      "iteration:  1580\n",
      "accuracy:  0.9410416666666667\n",
      "iteration:  1590\n",
      "accuracy:  0.9402083333333333\n",
      "iteration:  1600\n",
      "accuracy:  0.9370535714285714\n",
      "iteration:  1610\n",
      "accuracy:  0.9141369047619048\n",
      "iteration:  1620\n",
      "accuracy:  0.6424702380952381\n",
      "iteration:  1630\n",
      "accuracy:  0.9327380952380953\n",
      "iteration:  1640\n",
      "accuracy:  0.9370833333333334\n",
      "iteration:  1650\n",
      "accuracy:  0.9382440476190477\n",
      "iteration:  1660\n",
      "accuracy:  0.9393452380952381\n",
      "iteration:  1670\n",
      "accuracy:  0.9403571428571429\n",
      "iteration:  1680\n",
      "accuracy:  0.9405654761904761\n",
      "iteration:  1690\n",
      "accuracy:  0.9408035714285714\n",
      "iteration:  1700\n",
      "accuracy:  0.940952380952381\n",
      "iteration:  1710\n",
      "accuracy:  0.9412202380952381\n",
      "iteration:  1720\n",
      "accuracy:  0.9414880952380953\n",
      "iteration:  1730\n",
      "accuracy:  0.9416369047619048\n",
      "iteration:  1740\n",
      "accuracy:  0.9416369047619048\n",
      "iteration:  1750\n",
      "accuracy:  0.9417261904761904\n",
      "iteration:  1760\n",
      "accuracy:  0.9418452380952381\n",
      "iteration:  1770\n",
      "accuracy:  0.9419047619047619\n",
      "iteration:  1780\n",
      "accuracy:  0.9420238095238095\n",
      "iteration:  1790\n",
      "accuracy:  0.9422916666666666\n",
      "iteration:  1800\n",
      "accuracy:  0.9423809523809524\n",
      "iteration:  1810\n",
      "accuracy:  0.9423511904761904\n",
      "iteration:  1820\n",
      "accuracy:  0.9425297619047619\n",
      "iteration:  1830\n",
      "accuracy:  0.9426785714285715\n",
      "iteration:  1840\n",
      "accuracy:  0.9425595238095238\n",
      "iteration:  1850\n",
      "accuracy:  0.9423809523809524\n",
      "iteration:  1860\n",
      "accuracy:  0.9417857142857143\n",
      "iteration:  1870\n",
      "accuracy:  0.9396428571428571\n",
      "iteration:  1880\n",
      "accuracy:  0.9370535714285714\n",
      "iteration:  1890\n",
      "accuracy:  0.9408035714285714\n",
      "iteration:  1900\n",
      "accuracy:  0.942827380952381\n",
      "iteration:  1910\n",
      "accuracy:  0.9434821428571428\n",
      "iteration:  1920\n",
      "accuracy:  0.9436309523809524\n",
      "iteration:  1930\n",
      "accuracy:  0.9437202380952381\n",
      "iteration:  1940\n",
      "accuracy:  0.9436011904761905\n",
      "iteration:  1950\n",
      "accuracy:  0.9437202380952381\n",
      "iteration:  1960\n",
      "accuracy:  0.9433928571428571\n",
      "iteration:  1970\n",
      "accuracy:  0.9432440476190476\n",
      "iteration:  1980\n",
      "accuracy:  0.9423214285714285\n",
      "iteration:  1990\n",
      "accuracy:  0.940952380952381\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = train_network(x_train, t_train, 2000, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.81541837e-07 3.79616787e-14 1.54349262e-05 ... 1.56853697e-10\n",
      "  3.12215095e-07 2.35676586e-11]\n",
      " [1.11034958e-07 3.37286462e-05 8.22488869e-05 ... 4.83870208e-03\n",
      "  6.52548043e-03 8.18605782e-02]\n",
      " [1.33813035e-04 5.55841159e-06 7.33246802e-05 ... 6.24153323e-06\n",
      "  5.17652005e-03 1.19971149e-05]\n",
      " ...\n",
      " [4.33909511e-09 1.41671160e-15 9.99149172e-01 ... 9.91506844e-11\n",
      "  4.39295298e-09 8.74207277e-13]\n",
      " [4.51594139e-03 6.34696985e-07 6.88378027e-04 ... 2.62818625e-07\n",
      "  9.93050303e-01 3.54366983e-05]\n",
      " [1.57369022e-09 1.39377086e-05 9.97571385e-01 ... 4.97777354e-08\n",
      "  1.51786588e-03 1.38831157e-11]]\n",
      "0.9282142857142858\n"
     ]
    }
   ],
   "source": [
    "test_ans=test_network(x_val, t_val, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "def submission(x, W1, b1, W2, b2):\n",
    "    prop = propagation()\n",
    "    Y = prop.forward(x, W1, b1, W2, b2)\n",
    "    \n",
    "    return prediction(Y)\n",
    "\n",
    "test_data = pd.read_csv('Data/digit-recognizer/test.csv')\n",
    "test_data = np.array(test_data)\n",
    "m, n = test_data.shape\n",
    "\n",
    "ans=submission(test_data, W1, b1, W2, b2)\n",
    "print(ans)\n",
    "\n",
    "submission_dict = {\"ImageId\":np.array(range(1,m+1)),\"Label\":submission(test_data, W1, b1, W2, b2)}\n",
    "Submission = pd.DataFrame(submission_dict)\n",
    "Submission.head()\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
