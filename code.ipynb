{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "val_rate = 0.2\n",
    "val_num = int(data.shape[0] * val_rate)\n",
    "\n",
    "m, n=data.shape\n",
    "\n",
    "x_val = data[:val_num, 1:]\n",
    "t_val = data[:val_num, 0]\n",
    "x_train = data[val_num: , 1:]\n",
    "t_train = data[val_num: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.randn(784, 10) *0.01\n",
    "    b1 = np.zeros((1,10))\n",
    "    W2 = np.random.randn(10, 10) *0.01\n",
    "    b2 = np.zeros((1,10))\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "    x = x - np.max(x) \n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class propagation:\n",
    "    def __init__(self):\n",
    "        self.A1 = None\n",
    "        self.Z1 = None\n",
    "        self.A2 = None\n",
    "        self.Y = None\n",
    "        self.T = None\n",
    "        self.x = None\n",
    "        self.W2 = None\n",
    "    \n",
    "    def forward(self, x, W1, b1, W2, b2):\n",
    "        self.x = x\n",
    "        self.W2 = W2\n",
    "        self.A1 = np.dot(self.x, W1) + b1\n",
    "        self.Z1 = relu(self.A1)\n",
    "        self.A2 = np.dot(self.Z1, W2) + b2\n",
    "        self.Y = softmax(self.A2)\n",
    "    \n",
    "        return self.Y\n",
    "    \n",
    "    def backward(self, t):\n",
    "        self.T = one_hot(t)\n",
    "        m = self.T.size\n",
    "        dA2 = (self.Y - self.T) / m       #Nx10\n",
    "        dW2 = np.dot(self.Z1.T, dA2)   #10x10\n",
    "        db2 = np.sum(dA2, axis = 0)    \n",
    "        dZ1 = np.dot(dA2, self.W2.T)  #ã…’Nx10\n",
    "        dA1 = dZ1 * np.array(self.Z1 > 0, dtype=int) #Nx10\n",
    "        #dA1 = dZ1 * d_relu(self.Z1) \n",
    "        db1 = np.sum(dA1, axis = 0) \n",
    "        dW1 = np.dot(self.x.T, dA1)    #784x10\n",
    "        \n",
    "        return dW1, dW2, db1, db2\n",
    "def one_hot(x):\n",
    "    x.reshape(1, x.size)\n",
    "    batch_size = len(x)\n",
    "    t = np.zeros((batch_size, 10))\n",
    "    t[np.arange(batch_size), x] = 1\n",
    "    \n",
    "    return t    \n",
    "\n",
    "def SGD(W1, b1, W2, b2, dW1, dW2, db1, db2, learning_rate):\n",
    "    db1.reshape(1, db1.size)\n",
    "    db2.reshape(1, db2.size)\n",
    "    lr = learning_rate\n",
    "    W1 = W1 - lr * dW1\n",
    "    W2 = W2 - lr * dW2\n",
    "    b1 = b1 - lr * db1\n",
    "    b2 = b2 - lr * db2\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def prediction(Y):\n",
    "    return np.argmax(Y, axis = 1)\n",
    "\n",
    "def accuracy(Y, t):\n",
    "    K = prediction(Y)\n",
    "    t.reshape(1, t.size)\n",
    "    return np.sum(K == t) / K.size\n",
    "\n",
    "\n",
    "def train_network(x, t, iter, learning_rate):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    prop = propagation()\n",
    "    \n",
    "    for i in range(iter):\n",
    "        Y = prop.forward(x, W1, b1, W2, b2)\n",
    "        dW1, dW2, db1, db2 = prop.backward(t)\n",
    "        W1, b1, W2, b2 = SGD(W1, b1, W2, b2, dW1, dW2, db1, db2, learning_rate)\n",
    "        if (i%10 == 0):\n",
    "            print('iteration: ', i)\n",
    "            print('accuracy: ', accuracy(Y, t))\n",
    "            \n",
    "            \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def test_network(x, t, W1, b1, W2, b2):\n",
    "    prop = propagation()\n",
    "    Y = prop.forward(x, W1, b1, W2, b2)\n",
    "    print(Y)\n",
    "    print(accuracy(Y, t))\n",
    "    return prediction(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "accuracy:  0.10982142857142857\n",
      "iteration:  10\n",
      "accuracy:  0.48386904761904764\n",
      "iteration:  20\n",
      "accuracy:  0.5638690476190477\n",
      "iteration:  30\n",
      "accuracy:  0.7631845238095238\n",
      "iteration:  40\n",
      "accuracy:  0.7408630952380952\n",
      "iteration:  50\n",
      "accuracy:  0.7605357142857143\n",
      "iteration:  60\n",
      "accuracy:  0.7500892857142857\n",
      "iteration:  70\n",
      "accuracy:  0.8295238095238096\n",
      "iteration:  80\n",
      "accuracy:  0.8131845238095238\n",
      "iteration:  90\n",
      "accuracy:  0.8333333333333334\n",
      "iteration:  100\n",
      "accuracy:  0.8475595238095238\n",
      "iteration:  110\n",
      "accuracy:  0.8566964285714286\n",
      "iteration:  120\n",
      "accuracy:  0.8506547619047619\n",
      "iteration:  130\n",
      "accuracy:  0.8499107142857143\n",
      "iteration:  140\n",
      "accuracy:  0.8786904761904762\n",
      "iteration:  150\n",
      "accuracy:  0.8808333333333334\n",
      "iteration:  160\n",
      "accuracy:  0.875625\n",
      "iteration:  170\n",
      "accuracy:  0.8786904761904762\n",
      "iteration:  180\n",
      "accuracy:  0.8870833333333333\n",
      "iteration:  190\n",
      "accuracy:  0.8885416666666667\n",
      "iteration:  200\n",
      "accuracy:  0.877529761904762\n",
      "iteration:  210\n",
      "accuracy:  0.881547619047619\n",
      "iteration:  220\n",
      "accuracy:  0.8957142857142857\n",
      "iteration:  230\n",
      "accuracy:  0.898154761904762\n",
      "iteration:  240\n",
      "accuracy:  0.8991071428571429\n",
      "iteration:  250\n",
      "accuracy:  0.9001190476190476\n",
      "iteration:  260\n",
      "accuracy:  0.8964583333333334\n",
      "iteration:  270\n",
      "accuracy:  0.890922619047619\n",
      "iteration:  280\n",
      "accuracy:  0.9023809523809524\n",
      "iteration:  290\n",
      "accuracy:  0.9048809523809523\n",
      "iteration:  300\n",
      "accuracy:  0.905952380952381\n",
      "iteration:  310\n",
      "accuracy:  0.9063392857142857\n",
      "iteration:  320\n",
      "accuracy:  0.9072916666666667\n",
      "iteration:  330\n",
      "accuracy:  0.9050595238095238\n",
      "iteration:  340\n",
      "accuracy:  0.9045833333333333\n",
      "iteration:  350\n",
      "accuracy:  0.9083035714285714\n",
      "iteration:  360\n",
      "accuracy:  0.9110119047619047\n",
      "iteration:  370\n",
      "accuracy:  0.9124702380952381\n",
      "iteration:  380\n",
      "accuracy:  0.9129166666666667\n",
      "iteration:  390\n",
      "accuracy:  0.9134523809523809\n",
      "iteration:  400\n",
      "accuracy:  0.914345238095238\n",
      "iteration:  410\n",
      "accuracy:  0.9145535714285714\n",
      "iteration:  420\n",
      "accuracy:  0.914702380952381\n",
      "iteration:  430\n",
      "accuracy:  0.9149702380952381\n",
      "iteration:  440\n",
      "accuracy:  0.9157440476190476\n",
      "iteration:  450\n",
      "accuracy:  0.9168154761904762\n",
      "iteration:  460\n",
      "accuracy:  0.9176488095238096\n",
      "iteration:  470\n",
      "accuracy:  0.9183333333333333\n",
      "iteration:  480\n",
      "accuracy:  0.9189583333333333\n",
      "iteration:  490\n",
      "accuracy:  0.919375\n",
      "iteration:  500\n",
      "accuracy:  0.9202380952380952\n",
      "iteration:  510\n",
      "accuracy:  0.9204761904761904\n",
      "iteration:  520\n",
      "accuracy:  0.9208333333333333\n",
      "iteration:  530\n",
      "accuracy:  0.92125\n",
      "iteration:  540\n",
      "accuracy:  0.9214880952380953\n",
      "iteration:  550\n",
      "accuracy:  0.9213690476190476\n",
      "iteration:  560\n",
      "accuracy:  0.9213392857142857\n",
      "iteration:  570\n",
      "accuracy:  0.9216369047619047\n",
      "iteration:  580\n",
      "accuracy:  0.9214583333333334\n",
      "iteration:  590\n",
      "accuracy:  0.9215178571428572\n",
      "iteration:  600\n",
      "accuracy:  0.9221130952380953\n",
      "iteration:  610\n",
      "accuracy:  0.9234821428571428\n",
      "iteration:  620\n",
      "accuracy:  0.9245238095238095\n",
      "iteration:  630\n",
      "accuracy:  0.9255059523809523\n",
      "iteration:  640\n",
      "accuracy:  0.9258928571428572\n",
      "iteration:  650\n",
      "accuracy:  0.9266071428571429\n",
      "iteration:  660\n",
      "accuracy:  0.9269642857142857\n",
      "iteration:  670\n",
      "accuracy:  0.9274107142857143\n",
      "iteration:  680\n",
      "accuracy:  0.9277678571428571\n",
      "iteration:  690\n",
      "accuracy:  0.9280952380952381\n",
      "iteration:  700\n",
      "accuracy:  0.9280059523809524\n",
      "iteration:  710\n",
      "accuracy:  0.928125\n",
      "iteration:  720\n",
      "accuracy:  0.9278869047619047\n",
      "iteration:  730\n",
      "accuracy:  0.9277678571428571\n",
      "iteration:  740\n",
      "accuracy:  0.9276488095238096\n",
      "iteration:  750\n",
      "accuracy:  0.9278869047619047\n",
      "iteration:  760\n",
      "accuracy:  0.9280952380952381\n",
      "iteration:  770\n",
      "accuracy:  0.9292559523809524\n",
      "iteration:  780\n",
      "accuracy:  0.9301785714285714\n",
      "iteration:  790\n",
      "accuracy:  0.9311904761904762\n",
      "iteration:  800\n",
      "accuracy:  0.9316964285714285\n",
      "iteration:  810\n",
      "accuracy:  0.9321428571428572\n",
      "iteration:  820\n",
      "accuracy:  0.9322916666666666\n",
      "iteration:  830\n",
      "accuracy:  0.9325297619047619\n",
      "iteration:  840\n",
      "accuracy:  0.9325595238095238\n",
      "iteration:  850\n",
      "accuracy:  0.9326785714285715\n",
      "iteration:  860\n",
      "accuracy:  0.9325595238095238\n",
      "iteration:  870\n",
      "accuracy:  0.9325595238095238\n",
      "iteration:  880\n",
      "accuracy:  0.9327380952380953\n",
      "iteration:  890\n",
      "accuracy:  0.9327083333333334\n",
      "iteration:  900\n",
      "accuracy:  0.9327083333333334\n",
      "iteration:  910\n",
      "accuracy:  0.9326190476190476\n",
      "iteration:  920\n",
      "accuracy:  0.932797619047619\n",
      "iteration:  930\n",
      "accuracy:  0.9331547619047619\n",
      "iteration:  940\n",
      "accuracy:  0.9335416666666667\n",
      "iteration:  950\n",
      "accuracy:  0.9337797619047619\n",
      "iteration:  960\n",
      "accuracy:  0.9341071428571428\n",
      "iteration:  970\n",
      "accuracy:  0.9345535714285714\n",
      "iteration:  980\n",
      "accuracy:  0.9348511904761905\n",
      "iteration:  990\n",
      "accuracy:  0.9352083333333333\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = train_network(x_train, t_train, 1000, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.72676902e-03 1.22081855e-05 8.64675979e-04 ... 5.03166630e-01\n",
      "  1.13437084e-03 4.51495772e-01]\n",
      " [1.14912573e-03 5.83971478e-05 3.70855295e-02 ... 2.01850119e-06\n",
      "  1.71103443e-01 2.47941483e-03]\n",
      " [4.76235970e-05 1.54224096e-07 2.38411365e-02 ... 4.26419890e-02\n",
      "  1.55115277e-03 8.71191666e-01]\n",
      " ...\n",
      " [1.71142064e-06 5.60047771e-05 9.20433041e-04 ... 5.35960390e-03\n",
      "  2.83491562e-03 6.51280528e-02]\n",
      " [1.49453663e-08 9.89645327e-01 5.80203522e-03 ... 2.41405251e-04\n",
      "  2.21566200e-03 1.15360453e-04]\n",
      " [8.57045715e-05 1.35150799e-11 1.91172926e-05 ... 7.37853733e-04\n",
      "  2.41293673e-03 8.15442277e-01]]\n",
      "0.9245238095238095\n"
     ]
    }
   ],
   "source": [
    "test_ans=test_network(x_val, t_val, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 9 ... 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "def submission(x, W1, b1, W2, b2):\n",
    "    prop = propagation()\n",
    "    Y = prop.forward(x, W1, b1, W2, b2)\n",
    "    \n",
    "    return prediction(Y)\n",
    "\n",
    "test_data = pd.read_csv('Data/digit-recognizer/test.csv')\n",
    "test_data = np.array(test_data)\n",
    "m, n = test_data.shape\n",
    "\n",
    "ans=submission(test_data, W1, b1, W2, b2)\n",
    "print(ans)\n",
    "\n",
    "submission_dict = {\"ImageId\":np.array(range(1,m+1)),\"Label\":submission(test_data, W1, b1, W2, b2)}\n",
    "Submission = pd.DataFrame(submission_dict)\n",
    "Submission.head()\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
